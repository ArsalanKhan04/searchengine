{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15594b05-8aae-4078-ba6f-4fff6f8f8a7c",
   "metadata": {},
   "source": [
    "# Accessing and Using Lexicon\n",
    "\n",
    "### The lexicon is now stored in a pb file, it is time to retrieve it and use it accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1cd24e7-18f4-4e5c-903c-423eee0c577a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lexicon_proto_file_pb2 as lexproto\n",
    "lexicon_pb_path = r\"./lexicon.pb\"\n",
    "lexicon = lexproto.Lexicon()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1966f15e-4249-45f8-aa26-ea9379195716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15 ms, sys: 360 µs, total: 15.4 ms\n",
      "Wall time: 15.2 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1987612"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "with open(lexicon_pb_path, 'rb') as file:\n",
    "    protobufdata = file.read()\n",
    "lexicon.ParseFromString(protobufdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57334e61-3af3-43e8-9ee9-05cc5df5475d",
   "metadata": {},
   "source": [
    "### Time to make relevant functions\n",
    "\n",
    "- The lexicon has been created, but it is still important to make functions that can be used to use the lexicon in a meaningful way\n",
    "- For that purpose there are a few important functions to be made\n",
    "| Function | Purpose |\n",
    "| --- | --- |\n",
    "| GetWordID | Function that returns the actual word ID for each word |\n",
    "| UpdateLexicon | Considering there are additional words added to the lexicon, the following will be called to update our lexicon.pb file |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a45b5939-df93-4d86-9e23-a3e6393dd4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def UpdateLexicon(lexicon, filepath):\n",
    "    with open(filepath, 'wb') as f:\n",
    "        f.write(lexicon.SerializeToString())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adb6944-1cf3-479b-b75f-48db43e4c324",
   "metadata": {},
   "source": [
    "### Some important steps to take for GetWordID\n",
    "\n",
    "- We would get the word in raw form, so we will do the following steps to look for it:\n",
    "- We will check in order, if the word in the following forms is within the list:\n",
    "     - The Word Itself\n",
    "     - The word lemmatized as a noun\n",
    "     - The word lemmatized as a verb\n",
    "     - The word lemmatized as an adjective\n",
    "     - The word lemmatized as an adverb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3ccc70b-7bf3-4c76-a186-87bf2aed6a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.18 ms, sys: 3.69 ms, total: 12.9 ms\n",
      "Wall time: 12.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lexicon_list = list(lexicon.wordlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d566bec-0100-4172-bce1-f840499e0d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.23 ms, sys: 4.04 ms, total: 12.3 ms\n",
      "Wall time: 12.4 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9092"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "list(lexicon.wordlist).index(\"think\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "014983d4-6cea-4c7a-a0dd-8d90d26478ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 160 µs, sys: 0 ns, total: 160 µs\n",
      "Wall time: 163 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9092"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "lexicon_list.index(\"think\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9935d83-1657-466d-80cd-25618c5ba2a2",
   "metadata": {},
   "source": [
    "**Hence important to have a prebuilt python list always**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "648e21c8-4227-48c6-9faa-114cb88851c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'think'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatizer.lemmatize(\"thinks\", \"v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "033f60b8-11f4-4216-9ada-b7096be8e2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetWordID(word):\n",
    "    \n",
    "    try:\n",
    "        word_id = lexicon_list.index(word)\n",
    "        return word_id\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "    \n",
    "    for pos in ['n', 'v', 'a', 'r']:\n",
    "        lemmatized_word = lemmatizer.lemmatize(word, pos)\n",
    "        try:\n",
    "            word_id = lexicon_list.index(lemmatized_word)\n",
    "            return word_id\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "    word_id = len(lexicon_list)\n",
    "    lexicon_list.append(word)\n",
    "    return word_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "caf09f58-16fe-444f-bb51-23407ace841b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.37 ms, sys: 71 µs, total: 1.44 ms\n",
      "Wall time: 1.45 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9092"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "GetWordID(\"thinks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6ba1052b-1df8-4947-9367-be56bebf4425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 97 µs, sys: 5 µs, total: 102 µs\n",
      "Wall time: 105 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9092"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "GetWordID(\"think\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "91400e61-dea0-4ea1-86f0-ffc5b403c01d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.2 ms, sys: 0 ns, total: 13.2 ms\n",
      "Wall time: 13.2 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "147703"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "GetWordID(\"Arsalan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "244e67ba-4b42-4c98-8131-e3f313fd8cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.61 ms, sys: 84 µs, total: 1.7 ms\n",
      "Wall time: 1.7 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "147703"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "GetWordID(\"Arsalan\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbceed1f-a2dc-4a81-abbb-fae46c426ac9",
   "metadata": {},
   "source": [
    "This indicates maximum time is taken by words not in the list\n",
    "\n",
    "And once it is added, it doesn't take that long, so in an actual article, the time might not be that long"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67ad959-1a21-4133-8dd4-e70d56c76601",
   "metadata": {},
   "source": [
    "### To check our implementation, we will use the word list from wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18854789-b940-4fd4-b1a0-d85ada4acdc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "236736"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import words as wordcorpus\n",
    "words_all = wordcorpus.words()\n",
    "len(words_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f78abf3e-e62f-4bcf-ac61-94db6017918a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.4 s, sys: 0 ns, total: 27.4 s\n",
      "Wall time: 27.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "word_ids = [GetWordID(word.lower()) for word in lexicon_list[:100000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ae1ce21d-84af-40ff-ba68-88ab04659f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.1 ms, sys: 7 µs, total: 1.1 ms\n",
      "Wall time: 1.11 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "word_ids = [GetWordID(word.lower()) for word in lexicon_list[0:500]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3adb26-6562-4fd4-87fd-7aa0b21f0673",
   "metadata": {},
   "source": [
    "The results are very slow compared to what was expected, indicating the forward_index might take hours to be made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d2833b-5d2e-4924-ba9e-8631a82806a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
