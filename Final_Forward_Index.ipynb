{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b0d87e3-50ed-44d8-801e-228eb15f2fb2",
   "metadata": {},
   "source": [
    "# Making the final forward Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9bb718d-ad17-42ec-aecb-3d83d9f67853",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Data.saveFIndex.forwardindex_file_pb2 as fpb # Defining the proto buf data to store each element\n",
    "from parse_forward import parse # Getting each document element from here\n",
    "from wordlexicon import UpdateLexicon, lexicon_list # Updating the lexicon from here\n",
    "import lexicon.lexicon_proto_file_pb2 as lexproto # Using this to update the lexicon as well\n",
    "import os # using to get directory information of each json file\n",
    "import Data.metadata_pb2 as mpb # Getting the metadata\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "442e110b-c22b-4c03-aa38-0a2bbe9994f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Data.doc_data import save_docs as save_doc # Helper function to store the doc data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "28ae9a9d-eaa4-4cc5-86a2-62b4339ee057",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Data.doc_data.doc_file_pb2 as dpb # Storing the Doc ID with the data we will use to print later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e9cbb36-dae0-4346-8a45-36b88e1e5cfe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "CPU times: user 0 ns, sys: 1.2 ms, total: 1.2 ms\n",
      "Wall time: 857 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "metadata = mpb.MetaData()\n",
    "metadatafile_path = \"./Data/metadata.pb\"\n",
    "with open(metadatafile_path, \"rb\") as f:\n",
    "    filecontent = f.read()\n",
    "metadata.ParseFromString(filecontent)\n",
    "\n",
    "forwardindex_limit = metadata.forwardindexlimit\n",
    "total_docs = metadata.totaldocs\n",
    "currdir = os.getcwd()\n",
    "print(total_docs)\n",
    "print(forwardindex_limit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9d9ffb-9062-40c7-b84c-db9c6e6dc719",
   "metadata": {},
   "source": [
    "#### Making the forward index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "83ca4867-9a5f-4faa-b3e8-96c719428a66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147408"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_words = len(lexicon_list)\n",
    "total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a4dc4227-489a-4b45-8653-a01c79f5a952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mall_jsons\u001b[0m/  \u001b[01;34mdir_1\u001b[0m/  \u001b[01;34mdir_2\u001b[0m/  \u001b[01;34mdir_3\u001b[0m/  divfolders.ipynb\n"
     ]
    }
   ],
   "source": [
    "%ls JSONFILES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a834a98-a24a-42cf-9125-c10797fe72b7",
   "metadata": {},
   "source": [
    "#### Defining the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1543c55d-76b2-4ac3-b343-27951d5111ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['asiapacificresearch.json',\n",
       " 'azmirror.json',\n",
       " 'newyorkdailynews.json',\n",
       " 'nationalobserver.json',\n",
       " 'thedcclothesline.json',\n",
       " 'unian.json',\n",
       " 'curiousmindmagazine.json',\n",
       " 'australiannationalreview.json',\n",
       " 'theblaze.json',\n",
       " 'themindunleashed.json',\n",
       " 'nationalfile.json',\n",
       " 'anonnews.json',\n",
       " 'freedomainradio.json',\n",
       " 'eluxemagazine.json',\n",
       " 'thehuffingtonpostuk.json',\n",
       " 'newsmax.json',\n",
       " 'healthyfoodhouse.json',\n",
       " 'southfront.json',\n",
       " 'redstate.json',\n",
       " 'spiegel.json',\n",
       " 'motherjones.json',\n",
       " 'naturallysavvy.json',\n",
       " 'learntheriskorg.json',\n",
       " 'thefiscaltimes.json',\n",
       " 'hitandrun.json',\n",
       " 'foreignpolicy.json',\n",
       " 'healthsciencesinstitute.json',\n",
       " 'dailysignal.json',\n",
       " 'newsnetscotland.json',\n",
       " 'slate.json',\n",
       " 'vigilantcitizen.json',\n",
       " 'thehill.json',\n",
       " 'thoughtcrimeradio.json',\n",
       " 'scientificamerican.json',\n",
       " 'theguardian.json',\n",
       " 'healingoracle.json',\n",
       " 'thedailyexpress.json',\n",
       " 'dailywire.json',\n",
       " 'observer.json',\n",
       " 'committeeconstructivetomorrowcfactorg.json',\n",
       " 'thelibertydaily.json',\n",
       " 'thepoke.json',\n",
       " 'therightscoop.json',\n",
       " 'thedenverpost.json',\n",
       " 'alliancefornaturalhealthbiasjunkscience.json',\n",
       " 'campusreform.json',\n",
       " 'consciouslifenews.json',\n",
       " 'shadowproof.json',\n",
       " 'realclimatescience.json',\n",
       " 'obamawatcher.json',\n",
       " 'savethemales.json',\n",
       " 'usatoday.json',\n",
       " 'theborowitzreport.json',\n",
       " '21stcenturywire.json',\n",
       " 'nationalreview.json',\n",
       " 'newsbusters.json',\n",
       " 'truththeory.json',\n",
       " 'draxe.json',\n",
       " 'kidderminstershuttle.json',\n",
       " 'cnn.json',\n",
       " 'thegatewaypundit.json',\n",
       " 'jewworldorder.json',\n",
       " 'truthdig.json',\n",
       " 'sputnik.json',\n",
       " '369news.json',\n",
       " 'theweekuk.json',\n",
       " 'washingtontimes.json',\n",
       " 'trueactivist.json',\n",
       " 'greenmedinfo.json',\n",
       " 'freebeacon.json',\n",
       " 'thedailyecho.json',\n",
       " 'mercurynews.json',\n",
       " 'nowtheendbegins.json',\n",
       " 'infowars.json',\n",
       " 'dailykos.json',\n",
       " 'fortune.json',\n",
       " 'alternativemediatelevisionamtv.json',\n",
       " 'naturalhealth365.json',\n",
       " 'brightside.json',\n",
       " 'investorsbusinessdaily.json',\n",
       " 'france24.json',\n",
       " 'x22report.json',\n",
       " 'freedomdaily.json',\n",
       " 'buzzfeed.json',\n",
       " 'charlotteobserver.json',\n",
       " 'allianceforadvancedhealth.json',\n",
       " 'upi.json',\n",
       " 'realclearpolitics.json',\n",
       " 'mercola.json',\n",
       " 'investmentwatchblog.json',\n",
       " 'whatreallyhappened.json',\n",
       " 'beholdisrael.json',\n",
       " 'shareblue.json',\n",
       " 'birminghammail.json',\n",
       " 'wingsoverscotland.json',\n",
       " 'crooksandliars.json',\n",
       " 'evolutionnewsandviews.json',\n",
       " 'thedailymirror.json',\n",
       " 'newswars.json',\n",
       " 'theconservativetreehouse.json',\n",
       " 'thedailyblog.json',\n",
       " 'aljazeera.json',\n",
       " 'themichellemalkinblog.json',\n",
       " 'thescientist.json',\n",
       " 'therealnews.json',\n",
       " 'themanchestereveningnews.json',\n",
       " 'sgtreport.json',\n",
       " 'theintercept.json',\n",
       " 'theroot.json',\n",
       " 'humortimes.json',\n",
       " 'hotair.json',\n",
       " 'christianministriesinternational.json',\n",
       " 'capitalbnews.json',\n",
       " 'redoubtnews.json',\n",
       " 'larouchepac.json',\n",
       " 'theverge.json',\n",
       " 'scienceblogs.json',\n",
       " 'sustainablepulse.json',\n",
       " 'airwars.json',\n",
       " 'newspunch.json',\n",
       " 'welovetrump.json',\n",
       " 'dailyheraldchicago.json',\n",
       " 'politicususa.json',\n",
       " 'covertgeopolitics.json',\n",
       " 'washingtonpost.json',\n",
       " 'prepareforchange.json',\n",
       " 'fortruss.json',\n",
       " 'latimes.json',\n",
       " 'discoveryinstitute.json',\n",
       " 'pinknewsuk.json',\n",
       " 'newsweek.json',\n",
       " 'liveaction.json',\n",
       " 'dickmorrisblog.json',\n",
       " 'reuters.json',\n",
       " 'lisahaven.json',\n",
       " 'rferl.json',\n",
       " 'rawstory.json',\n",
       " 'informnapalm.json',\n",
       " 'anonymous.json',\n",
       " 'thestream.json',\n",
       " 'sluggerotoole.json',\n",
       " 'trunews.json',\n",
       " 'theirishtimes.json',\n",
       " 'bbcuk.json',\n",
       " 'freethoughtproject.json',\n",
       " 'theepochtimes.json',\n",
       " 'labourlist.json',\n",
       " 'dailybeast.json',\n",
       " 'wattsupwiththat.json',\n",
       " 'jacobinmag.json',\n",
       " 'theatlantic.json',\n",
       " 'sottnet.json',\n",
       " 'thecollegefix.json',\n",
       " 'thenation.json',\n",
       " 'collective-evolution.json',\n",
       " 'ecowatch.json',\n",
       " 'americanintelligencemedia.json',\n",
       " 'theamericanconservative.json',\n",
       " 'thoughtcatalog.json',\n",
       " 'westernjournal.json',\n",
       " 'eveningstandard.json',\n",
       " 'politicalite.json',\n",
       " 'wakingtimes.json',\n",
       " 'wnd.json',\n",
       " 'mediaroots.json',\n",
       " 'independentsciencenews.json',\n",
       " 'environmentalworkinggroupewg.json',\n",
       " 'russia-insider.json',\n",
       " 'thetelegraph.json',\n",
       " 'powerlineblog.json',\n",
       " 'yna.json',\n",
       " 'tass.json',\n",
       " 'trendingpolitics.json',\n",
       " 'theheartysoul.json',\n",
       " 'allianceadvancedhealth.json',\n",
       " 'thedailyrecord.json',\n",
       " 'greenwichtime.json',\n",
       " 'channel4uk.json',\n",
       " 'livescience.json',\n",
       " 'thespoof.json',\n",
       " 'cityam.json',\n",
       " 'mcclatchydc.json',\n",
       " 'theshovel.json',\n",
       " 'themoscowtimes.json',\n",
       " 'usahitman.json',\n",
       " 'infiniteunknown.json',\n",
       " 'lifespa.json',\n",
       " 'thewashingtonexaminer.json',\n",
       " 'themillenniumreport.json',\n",
       " 'shtfplan.json',\n",
       " 'jerusalempost.json',\n",
       " 'bbc.json',\n",
       " 'modernalternativemama.json',\n",
       " 'escapeallthesethings.json',\n",
       " 'breaking911.json',\n",
       " 'nutritionfactsorg.json',\n",
       " 'anti-impreialist.json',\n",
       " 'skynewspolitics.json',\n",
       " 'osce.json',\n",
       " 'dailyhealthpost.json',\n",
       " 'therussophileorg.json',\n",
       " 'theonion.json',\n",
       " 'physicsworld.json',\n",
       " 'greatgameindia.json',\n",
       " 'veteranstoday.json',\n",
       " 'thesmokinggun.json',\n",
       " 'vaxxter.json',\n",
       " 'notrickszone.json',\n",
       " 'vox.json',\n",
       " 'thenewyorktimes.json',\n",
       " 'iowaclimatescienceeducation.json',\n",
       " 'globalresearch.json',\n",
       " 'collectiveevolution.json',\n",
       " 'crikey.json',\n",
       " 'pamelagellerreport.json',\n",
       " 'pbs.json',\n",
       " 'needtoknow.json',\n",
       " 'metrouk.json',\n",
       " 'talkingpointsmemo.json',\n",
       " 'usnews.json',\n",
       " 'thetennesseestar.json',\n",
       " 'thesun.json',\n",
       " 'yahoonews.json',\n",
       " 'newyorkpost.json',\n",
       " 'newyorker.json',\n",
       " 'rollcall.json',\n",
       " 'naturalnews.json',\n",
       " 'zerohedge.json',\n",
       " 'returntonow.json',\n",
       " 'offguardian.json',\n",
       " 'ageofautism.json',\n",
       " 'newrepublic.json',\n",
       " 'warroom.json',\n",
       " 'wizbang.json',\n",
       " 'activistpost.json',\n",
       " 'wearechange.json',\n",
       " 'newsinsideoutcom.json',\n",
       " 'djhj.json',\n",
       " 'familysurvivalheadlines.json',\n",
       " 'msnbc.json',\n",
       " 'acnlatitudes.json',\n",
       " 'theseattletimes.json',\n",
       " 'rt.json',\n",
       " 'thewashingtonstandard.json',\n",
       " 'weareanonymous.json',\n",
       " 'trumptimes.json',\n",
       " 'divfolders.ipynb',\n",
       " '911truthorg.json',\n",
       " 'lewrockwell.json',\n",
       " 'thedailycaller.json',\n",
       " 'freedom-bunker.json',\n",
       " 'thewakingtimes.json',\n",
       " 'shoebat.json',\n",
       " 'iheartintelligence.json',\n",
       " 'foxnews.json',\n",
       " 'climatism.json',\n",
       " 'healthimpactnews.json',\n",
       " 'bearingarms.json',\n",
       " 'thebl.json',\n",
       " 'truthout.json',\n",
       " 'noqreport.json',\n",
       " 'adobochronicles.json',\n",
       " 'abcnews.json',\n",
       " 'jesusdaily.json',\n",
       " 'thechaser.json',\n",
       " 'realstrategy.json',\n",
       " 'chicagotribune.json',\n",
       " 'remnantnewspaper.json',\n",
       " 'dailygrail.json',\n",
       " 'theduran.json',\n",
       " 'skeptiko.json',\n",
       " 'cbsnews.json',\n",
       " 'alliancefornaturalhealth.json',\n",
       " 'althealthworks.json',\n",
       " 'dailymail.json',\n",
       " 'csmonitor.json',\n",
       " 'disclosetv.json',\n",
       " 'lawenforcementtoday.json',\n",
       " 'rightwingwatch.json',\n",
       " 'thebeaverton.json',\n",
       " 'stillnessinthestorm.json',\n",
       " 'palmerreport.json',\n",
       " 'foreverconscious.json',\n",
       " 'urbanintellectuals.json',\n",
       " 'breitbart.json',\n",
       " 'prntly.json',\n",
       " 'dailyposter.json',\n",
       " 'higherperspective.json',\n",
       " 'climateetc.json',\n",
       " 'washingtonmonthly.json',\n",
       " 'thehuffingtonpost.json',\n",
       " 'conspiracydailyupdate.json',\n",
       " 'illuminatiwatcher.json',\n",
       " 'cnbc.json',\n",
       " 'ancientcode.json',\n",
       " 'alternativemediatv.json',\n",
       " 'democracynow.json',\n",
       " 'realnewsrightnow.json',\n",
       " 'viralnewsnetwork.json',\n",
       " 'thevaccinereaction.json',\n",
       " 'mintpressnews.json',\n",
       " 'courthousenews.json',\n",
       " 'coloradopeakpolitics.json',\n",
       " 'awarenessact.json',\n",
       " 'drudgereport.json',\n",
       " 'skynewsus.json',\n",
       " 'windowoneurasiablog.json',\n",
       " 'bigleaguepolitics.json',\n",
       " 'davidwolfe.json',\n",
       " 'politico.json',\n",
       " 'faithpanda.json',\n",
       " 'fivethirthyeight.json',\n",
       " 'vdare.json',\n",
       " 'presswatchers.json',\n",
       " 'politicalwire.json',\n",
       " 'healthyholisticliving.json',\n",
       " 'occupydemocrats.json',\n",
       " 'climatedepot.json',\n",
       " 'npr.json',\n",
       " 'instapundit.json',\n",
       " 'bipartisanreport.json',\n",
       " 'anonymousconservative.json',\n",
       " 'lifesitenews.json',\n",
       " 'conservativehome.json',\n",
       " 'jesusissavior.json',\n",
       " 'renegadetribune.json',\n",
       " 'pravadareport.json',\n",
       " 'greenpeace.json',\n",
       " 'humansarefree.json',\n",
       " 'thelibertybeacon.json',\n",
       " 'naturalawakeningsmagazine.json',\n",
       " 'fivethirtyeight.json',\n",
       " 'oann.json',\n",
       " 'bonginoreport.json',\n",
       " 'whatfinger.json',\n",
       " 'theindependent.json',\n",
       " 'cosmicintelligenceagency.json',\n",
       " 'haarpnet.json',\n",
       " 'chicagosun-times.json',\n",
       " 'thehuffingtonpostpoliticalsatire.json',\n",
       " 'thetruthaboutcancer.json',\n",
       " 'davidicke.json',\n",
       " 'nationalinterest.json',\n",
       " 'deneenborelli.json',\n",
       " 'livingwhole.json',\n",
       " 'dailybuzzlive.json',\n",
       " 'alternet.json',\n",
       " 'realjewnews.json',\n",
       " 'ukcolumn.json',\n",
       " 'ipolitics.json',\n",
       " 'newslo.json',\n",
       " 'thepoliticalinsider.json',\n",
       " 'clashdaily.json',\n",
       " 'thecorbettreport.json',\n",
       " 'saraacater.json',\n",
       " 'endtimeheadlines.json',\n",
       " 'petapeoplefortheethicaltreatmentofanimals.json',\n",
       " 'naturalcures.json',\n",
       " 'geoengineeringwatch.json',\n",
       " 'theguardianuk.json',\n",
       " 'thebulwark.json',\n",
       " 'summitnews.json']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('JSONFILES/all_jsons')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ef034668-e22b-434e-a43e-0c994159a1bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': \"newsmax--2022-01-01--Rep. Murphy to Newsmax: AOC, Pelosi in 'Fantasy World' Over Tax Plans\",\n",
       " 'date': '2022-01-01',\n",
       " 'source': 'newsmax',\n",
       " 'title': \"Rep. Murphy to Newsmax: AOC, Pelosi in 'Fantasy World' Over Tax Plans\",\n",
       " 'content': \"House Speaker Nancy Pelosi and Rep. Alexandria Ocasio-Cortez are living in a `` fantasy world with unicorns and butterflies '' if they think the government can `` take other people 's money '' and pay for liberal agenda initiatives , Rep. Greg Murphy said on Newsmax Saturday .\\n`` You know , I was sent something the other day from the IRS ruling that if you stole property , you were supposed to report that as income , '' the North Carolina Republican , who appeared on Newsmax 's `` Saturday Report '' with fellow Rep. Don Bacon , R-Neb.\\n@ @ @ @ @ @ @ Democrats ' world is this possible . ''\\nHe added that the Democrats ' calls for capital gains taxes , which are being rejected by Americans , is a `` total farce . ''\\n`` This is grand larceny of the American people because here you are , [ potentially ] being taxed for something that may never come to fruition , '' said Murphy .\\nBacon said he believes `` they lost middle America '' with the proposal , so the Democrats may have retreated from it , but still the spending @ @ @ @ @ @ @ all these budget gimmicks '' that contained years of raising taxes .\\n`` They 're looking to find pockets of money that they do n't have access to , and one of them is all these unrealized capital gains , '' said Bacon .\\n`` You 're earning 5 % to 10 % on a certain account , and you 're paying tax on it and then , say 5 years into it , you take a loss .\\nBut what happens then ?\\nDo you get the credit ? ''\\nBacon also @ @ @ @ @ @ @ , R-Ky. , for putting out his annual `` Festivus '' grievance report , which shows that `` we can tighten our belts .\\n`` [ Democrats are ] trying to transform America with a 50-50 Senate and a five-seat majority in the House…Americans did n't want far-left Bernie Sanders welfare state policies .\\nThey 're looking for centrist , reasonable , pragmatic governance in a split country . ''\\nThe congressmen also criticized the call for federal mandates over the COVID-19 pandemic .\\n`` I think it 's reasonable to say that @ @ @ @ @ @ @ flying it , and I 'm just going to give a little bit of leeway to decisions that have been made , '' said Murphy .\\n`` The problem is you know , Fauci has come out with this know-it-all arrogance that has dissuaded the American people . ''\\nMurphy , who is also a physician , said he does feel for his hospital colleagues who have been `` overworked and slammed for two years , '' but he also said the `` numbers are not nearly what they 're said to be @ @ @ @ @ @ @ will hear arguments on Jan. 7 over President Joe Biden 's vaccine mandates , and Bacon said he does not think it will pass muster .\\n`` At a minimum , you need a law where the House and the Senate passed a version of this bill , '' he said .\\n`` I hope that the Supreme Court reins in this dictatorial power that President Biden thinks he has .\\nBut we 'll see .\\nBut I 'm hopeful that they will rein his power in . ''\\nNote : See Newsmax @ @ @ @ @ @ @ million U.S. homes , on DirecTV Ch .\\n349 , Dish Network Ch .\\n216 , Xfinity Ch .\\n1115 , Spectrum , U-verse Ch .\\n1220 , FiOS Ch .\\n615 , Frontier Ch .\\n115 , Optimum Ch .\\n102 , Cox cable , Suddenlink Ch .\\n102 , Mediacom Ch .\\n277 , AT & T TV Ch 349 , FUBO and major OTT platforms like Roku , YouTube , Xumo , Pluto and most smart TV ’ s including Samsung+ , Sony , LG , Vizio and more – @ @ @ @ @ @ @ Click Here\",\n",
       " 'author': '',\n",
       " 'url': 'https://www.newsmax.com/politics/greg-murphy-don-bacon-democrats-taxes/2022/01/01/id/1050658',\n",
       " 'published': 'Sat, 01 Jan 2022 12:06:23 EDT',\n",
       " 'published_utc': 1641056783,\n",
       " 'collection_utc': 1641081150}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"JSONFILES/all_jsons/newsmax.json\", 'r') as f:\n",
    "   json_data = json.load(f)\n",
    "json_data[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d42f2ba7-963c-4ef3-bdd7-3f05f0dd47bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addFIndex(dir_start, dir_end, no_of_barrels):\n",
    "    doc_id = total_docs\n",
    "    forwardindex = fpb.ForwardIndex()\n",
    "    doc_data = dpb.DocData()\n",
    "    count = 0\n",
    "    start_time = time.time()\n",
    "    for dir_index in range(dir_start, dir_end):\n",
    "        dir_to_parse =  f\"./JSONFILES/dir_{dir_index}\"\n",
    "        list_of_jsons = os.listdir(dir_to_parse)\n",
    "        for each_json in list_of_jsons:\n",
    "            json_path = os.path.join(dir_to_parse, each_json)\n",
    "    \n",
    "            with open(json_path, 'r') as f:\n",
    "                data = json.load(f)\n",
    "                for eacharticle in data:\n",
    "                    forwardindex.docelement.append(parse(eacharticle, doc_id))\n",
    "                    doc_data.eachdoc.append(save_doc.parse(eacharticle))\n",
    "                    doc_id += 1\n",
    "                    count += 1\n",
    "                    if count % 500 == 0:\n",
    "                        end_time = time.time()\n",
    "                        print(count, \"/\", no_of_barrels*forwardindex_limit, \" completed\")\n",
    "                        time_taken = end_time-start_time\n",
    "                        print(f\"Time taken: {time_taken}\") \n",
    "                        start_time = time.time()\n",
    "                        \n",
    "                    if doc_id % forwardindex_limit == 0:\n",
    "                        data_content = forwardindex.SerializeToString()\n",
    "                        with open(f\"./Data/forward_index/findex_{(doc_id//forwardindex_limit) - 1}.pb\", \"wb\") as f:\n",
    "                            f.write(data_content)\n",
    "                        forwardindex = fpb.ForwardIndex()\n",
    "                    if count / forwardindex_limit == no_of_barrels:\n",
    "                        metadata.totaldocs = doc_id\n",
    "                        print(\"Total final docs = \", doc_id)\n",
    "                        with open(metadatafile_path, \"wb\") as f:\n",
    "                            f.write(metadata.SerializeToString())\n",
    "                        lexicon = lexproto.Lexicon()\n",
    "                        lexicon.wordlist.extend(lexicon_list)\n",
    "                        UpdateLexicon(lexicon)\n",
    "                        return\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8d82fc55-c72b-4767-aba0-94610ada26ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 / 110000  completed\n",
      "Time taken: 162.44662618637085\n",
      "1000 / 110000  completed\n",
      "Time taken: 152.0184452533722\n",
      "1500 / 110000  completed\n",
      "Time taken: 156.06553530693054\n",
      "2000 / 110000  completed\n",
      "Time taken: 166.54598546028137\n",
      "2500 / 110000  completed\n",
      "Time taken: 162.90471172332764\n",
      "3000 / 110000  completed\n",
      "Time taken: 157.73294925689697\n",
      "3500 / 110000  completed\n",
      "Time taken: 172.22956657409668\n",
      "4000 / 110000  completed\n",
      "Time taken: 162.1533694267273\n",
      "4500 / 110000  completed\n",
      "Time taken: 149.28699731826782\n",
      "5000 / 110000  completed\n",
      "Time taken: 142.3312270641327\n",
      "5500 / 110000  completed\n",
      "Time taken: 138.86605548858643\n",
      "6000 / 110000  completed\n",
      "Time taken: 141.30926132202148\n",
      "6500 / 110000  completed\n",
      "Time taken: 142.79642367362976\n",
      "7000 / 110000  completed\n",
      "Time taken: 142.50509023666382\n",
      "7500 / 110000  completed\n",
      "Time taken: 146.1170153617859\n",
      "8000 / 110000  completed\n",
      "Time taken: 143.81211304664612\n",
      "8500 / 110000  completed\n",
      "Time taken: 144.23888421058655\n",
      "9000 / 110000  completed\n",
      "Time taken: 141.22987747192383\n",
      "9500 / 110000  completed\n",
      "Time taken: 145.13815665245056\n",
      "10000 / 110000  completed\n",
      "Time taken: 144.6593840122223\n",
      "10500 / 110000  completed\n",
      "Time taken: 150.60989499092102\n",
      "11000 / 110000  completed\n",
      "Time taken: 141.6781530380249\n",
      "11500 / 110000  completed\n",
      "Time taken: 146.92918014526367\n",
      "12000 / 110000  completed\n",
      "Time taken: 148.35394430160522\n",
      "12500 / 110000  completed\n",
      "Time taken: 144.9111783504486\n",
      "13000 / 110000  completed\n",
      "Time taken: 147.492014169693\n",
      "13500 / 110000  completed\n",
      "Time taken: 148.52729153633118\n",
      "14000 / 110000  completed\n",
      "Time taken: 148.05333805084229\n",
      "14500 / 110000  completed\n",
      "Time taken: 141.94066452980042\n",
      "15000 / 110000  completed\n",
      "Time taken: 141.99150824546814\n",
      "15500 / 110000  completed\n",
      "Time taken: 148.64943408966064\n",
      "16000 / 110000  completed\n",
      "Time taken: 146.71872210502625\n",
      "16500 / 110000  completed\n",
      "Time taken: 150.6813099384308\n",
      "17000 / 110000  completed\n",
      "Time taken: 154.82385993003845\n",
      "17500 / 110000  completed\n",
      "Time taken: 142.82889223098755\n",
      "18000 / 110000  completed\n",
      "Time taken: 143.01993703842163\n",
      "18500 / 110000  completed\n",
      "Time taken: 146.240975856781\n",
      "19000 / 110000  completed\n",
      "Time taken: 147.50657272338867\n",
      "19500 / 110000  completed\n",
      "Time taken: 142.64175128936768\n",
      "20000 / 110000  completed\n",
      "Time taken: 137.56702303886414\n",
      "20500 / 110000  completed\n",
      "Time taken: 144.33816027641296\n",
      "21000 / 110000  completed\n",
      "Time taken: 134.93740057945251\n",
      "21500 / 110000  completed\n",
      "Time taken: 143.43116879463196\n",
      "22000 / 110000  completed\n",
      "Time taken: 137.98765087127686\n",
      "22500 / 110000  completed\n",
      "Time taken: 158.0877411365509\n",
      "23000 / 110000  completed\n",
      "Time taken: 159.00128841400146\n",
      "23500 / 110000  completed\n",
      "Time taken: 147.00666785240173\n",
      "24000 / 110000  completed\n",
      "Time taken: 148.85985207557678\n",
      "24500 / 110000  completed\n",
      "Time taken: 144.38270235061646\n",
      "25000 / 110000  completed\n",
      "Time taken: 147.32504415512085\n",
      "25500 / 110000  completed\n",
      "Time taken: 149.613951921463\n",
      "26000 / 110000  completed\n",
      "Time taken: 144.68486046791077\n",
      "26500 / 110000  completed\n",
      "Time taken: 149.75826406478882\n",
      "27000 / 110000  completed\n",
      "Time taken: 153.86322712898254\n",
      "27500 / 110000  completed\n",
      "Time taken: 149.74089455604553\n",
      "28000 / 110000  completed\n",
      "Time taken: 160.77045464515686\n",
      "28500 / 110000  completed\n",
      "Time taken: 151.14250874519348\n",
      "29000 / 110000  completed\n",
      "Time taken: 141.72112584114075\n",
      "29500 / 110000  completed\n",
      "Time taken: 148.6555676460266\n",
      "30000 / 110000  completed\n",
      "Time taken: 147.83158373832703\n",
      "30500 / 110000  completed\n",
      "Time taken: 146.5858654975891\n",
      "31000 / 110000  completed\n",
      "Time taken: 154.92790937423706\n",
      "31500 / 110000  completed\n",
      "Time taken: 157.55798983573914\n",
      "32000 / 110000  completed\n",
      "Time taken: 152.24165272712708\n",
      "32500 / 110000  completed\n",
      "Time taken: 156.76673913002014\n",
      "33000 / 110000  completed\n",
      "Time taken: 188.62755727767944\n",
      "33500 / 110000  completed\n",
      "Time taken: 176.9407923221588\n",
      "34000 / 110000  completed\n",
      "Time taken: 177.03253173828125\n",
      "34500 / 110000  completed\n",
      "Time taken: 156.9378468990326\n",
      "35000 / 110000  completed\n",
      "Time taken: 153.72618794441223\n",
      "35500 / 110000  completed\n",
      "Time taken: 177.44699120521545\n",
      "36000 / 110000  completed\n",
      "Time taken: 167.6964144706726\n",
      "36500 / 110000  completed\n",
      "Time taken: 158.2746922969818\n",
      "37000 / 110000  completed\n",
      "Time taken: 163.45297765731812\n",
      "37500 / 110000  completed\n",
      "Time taken: 178.77124071121216\n",
      "38000 / 110000  completed\n",
      "Time taken: 162.14932012557983\n",
      "38500 / 110000  completed\n",
      "Time taken: 163.98269486427307\n",
      "39000 / 110000  completed\n",
      "Time taken: 165.51533031463623\n",
      "39500 / 110000  completed\n",
      "Time taken: 171.93716716766357\n",
      "40000 / 110000  completed\n",
      "Time taken: 172.37989592552185\n",
      "40500 / 110000  completed\n",
      "Time taken: 186.09677481651306\n",
      "41000 / 110000  completed\n",
      "Time taken: 195.26266479492188\n",
      "41500 / 110000  completed\n",
      "Time taken: 172.85019993782043\n",
      "42000 / 110000  completed\n",
      "Time taken: 182.67704725265503\n",
      "42500 / 110000  completed\n",
      "Time taken: 181.16628742218018\n",
      "43000 / 110000  completed\n",
      "Time taken: 189.67973351478577\n",
      "43500 / 110000  completed\n",
      "Time taken: 169.8896188735962\n",
      "44000 / 110000  completed\n",
      "Time taken: 174.04105067253113\n",
      "44500 / 110000  completed\n",
      "Time taken: 184.22680807113647\n",
      "45000 / 110000  completed\n",
      "Time taken: 174.79967379570007\n",
      "45500 / 110000  completed\n",
      "Time taken: 164.0313675403595\n",
      "46000 / 110000  completed\n",
      "Time taken: 170.0378122329712\n",
      "46500 / 110000  completed\n",
      "Time taken: 188.69454383850098\n",
      "47000 / 110000  completed\n",
      "Time taken: 201.64720058441162\n",
      "47500 / 110000  completed\n",
      "Time taken: 174.22014117240906\n",
      "48000 / 110000  completed\n",
      "Time taken: 191.8432960510254\n",
      "48500 / 110000  completed\n",
      "Time taken: 180.13026094436646\n",
      "49000 / 110000  completed\n",
      "Time taken: 182.57558941841125\n",
      "49500 / 110000  completed\n",
      "Time taken: 188.8298635482788\n",
      "50000 / 110000  completed\n",
      "Time taken: 175.53468704223633\n",
      "50500 / 110000  completed\n",
      "Time taken: 181.3475902080536\n",
      "51000 / 110000  completed\n",
      "Time taken: 184.03812217712402\n",
      "51500 / 110000  completed\n",
      "Time taken: 190.18375253677368\n",
      "52000 / 110000  completed\n",
      "Time taken: 179.34715723991394\n",
      "52500 / 110000  completed\n",
      "Time taken: 184.11679339408875\n",
      "53000 / 110000  completed\n",
      "Time taken: 166.63521027565002\n",
      "53500 / 110000  completed\n",
      "Time taken: 183.40669798851013\n",
      "54000 / 110000  completed\n",
      "Time taken: 176.5482988357544\n",
      "54500 / 110000  completed\n",
      "Time taken: 196.68975639343262\n",
      "55000 / 110000  completed\n",
      "Time taken: 200.86052680015564\n",
      "55500 / 110000  completed\n",
      "Time taken: 194.60725164413452\n",
      "56000 / 110000  completed\n",
      "Time taken: 187.38619089126587\n",
      "56500 / 110000  completed\n",
      "Time taken: 202.0951657295227\n",
      "57000 / 110000  completed\n",
      "Time taken: 185.06721949577332\n",
      "57500 / 110000  completed\n",
      "Time taken: 196.24536442756653\n",
      "58000 / 110000  completed\n",
      "Time taken: 198.55648708343506\n",
      "58500 / 110000  completed\n",
      "Time taken: 223.25668954849243\n",
      "59000 / 110000  completed\n",
      "Time taken: 191.0716826915741\n",
      "59500 / 110000  completed\n",
      "Time taken: 190.45127868652344\n",
      "60000 / 110000  completed\n",
      "Time taken: 187.6062331199646\n",
      "60500 / 110000  completed\n",
      "Time taken: 210.92890286445618\n",
      "61000 / 110000  completed\n",
      "Time taken: 195.7306408882141\n",
      "61500 / 110000  completed\n",
      "Time taken: 195.91593718528748\n",
      "62000 / 110000  completed\n",
      "Time taken: 192.5727081298828\n",
      "62500 / 110000  completed\n",
      "Time taken: 187.77309036254883\n",
      "63000 / 110000  completed\n",
      "Time taken: 193.32336282730103\n",
      "63500 / 110000  completed\n",
      "Time taken: 202.03749895095825\n",
      "64000 / 110000  completed\n",
      "Time taken: 213.73603582382202\n",
      "64500 / 110000  completed\n",
      "Time taken: 188.40017676353455\n",
      "65000 / 110000  completed\n",
      "Time taken: 187.45109724998474\n",
      "65500 / 110000  completed\n",
      "Time taken: 190.17140221595764\n",
      "66000 / 110000  completed\n",
      "Time taken: 183.6695261001587\n",
      "66500 / 110000  completed\n",
      "Time taken: 197.52682948112488\n",
      "67000 / 110000  completed\n",
      "Time taken: 190.34159588813782\n",
      "67500 / 110000  completed\n",
      "Time taken: 204.94468879699707\n",
      "68000 / 110000  completed\n",
      "Time taken: 192.78478169441223\n",
      "68500 / 110000  completed\n",
      "Time taken: 186.02737760543823\n",
      "69000 / 110000  completed\n",
      "Time taken: 197.0129108428955\n",
      "69500 / 110000  completed\n",
      "Time taken: 192.59162950515747\n",
      "70000 / 110000  completed\n",
      "Time taken: 198.85255360603333\n",
      "70500 / 110000  completed\n",
      "Time taken: 192.35638570785522\n",
      "71000 / 110000  completed\n",
      "Time taken: 211.53212761878967\n",
      "71500 / 110000  completed\n",
      "Time taken: 196.1874361038208\n",
      "72000 / 110000  completed\n",
      "Time taken: 195.26944255828857\n",
      "72500 / 110000  completed\n",
      "Time taken: 203.7434229850769\n",
      "73000 / 110000  completed\n",
      "Time taken: 201.6081087589264\n",
      "73500 / 110000  completed\n",
      "Time taken: 197.8779764175415\n",
      "74000 / 110000  completed\n",
      "Time taken: 208.32287502288818\n",
      "74500 / 110000  completed\n",
      "Time taken: 211.37781715393066\n",
      "75000 / 110000  completed\n",
      "Time taken: 209.34881901741028\n",
      "75500 / 110000  completed\n",
      "Time taken: 187.15537858009338\n",
      "76000 / 110000  completed\n",
      "Time taken: 196.4200475215912\n",
      "76500 / 110000  completed\n",
      "Time taken: 197.5565013885498\n",
      "77000 / 110000  completed\n",
      "Time taken: 190.5161418914795\n",
      "77500 / 110000  completed\n",
      "Time taken: 223.34359312057495\n",
      "78000 / 110000  completed\n",
      "Time taken: 217.06415915489197\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0x91 in position 133029889: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43maddFIndex\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m11\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[27], line 14\u001b[0m, in \u001b[0;36maddFIndex\u001b[0;34m(dir_start, dir_end, no_of_barrels)\u001b[0m\n\u001b[1;32m     11\u001b[0m json_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dir_to_parse, each_json)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(json_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 14\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m eacharticle \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[1;32m     16\u001b[0m         forwardindex\u001b[38;5;241m.\u001b[39mdocelement\u001b[38;5;241m.\u001b[39mappend(parse(eacharticle, doc_id))\n",
      "File \u001b[0;32m/usr/lib/python3.10/json/__init__.py:293\u001b[0m, in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(fp, \u001b[38;5;241m*\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    275\u001b[0m         parse_int\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_constant\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_pairs_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[1;32m    276\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;124;03m    a JSON document) to a Python object.\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;124;03m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loads(\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    294\u001b[0m         \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcls\u001b[39m, object_hook\u001b[38;5;241m=\u001b[39mobject_hook,\n\u001b[1;32m    295\u001b[0m         parse_float\u001b[38;5;241m=\u001b[39mparse_float, parse_int\u001b[38;5;241m=\u001b[39mparse_int,\n\u001b[1;32m    296\u001b[0m         parse_constant\u001b[38;5;241m=\u001b[39mparse_constant, object_pairs_hook\u001b[38;5;241m=\u001b[39mobject_pairs_hook, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[0;32m/usr/lib/python3.10/codecs.py:322\u001b[0m, in \u001b[0;36mBufferedIncrementalDecoder.decode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;66;03m# decode input (taking the buffer into account)\u001b[39;00m\n\u001b[1;32m    321\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer \u001b[38;5;241m+\u001b[39m \u001b[38;5;28minput\u001b[39m\n\u001b[0;32m--> 322\u001b[0m     (result, consumed) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_buffer_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;66;03m# keep undecoded input until the next call\u001b[39;00m\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer \u001b[38;5;241m=\u001b[39m data[consumed:]\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x91 in position 133029889: invalid start byte"
     ]
    }
   ],
   "source": [
    "addFIndex(1, 4, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d25f2b62-d2b1-468c-92aa-6fb35fc68310",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/arsal4an/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e5f7ee2c-cc52-442b-9dd8-03aa0b1c9f94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240956"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lexicon_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7c6e7d0c-a280-4073-9679-6911fbc808ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "findex_0.pb  findex_2.pb  findex_4.pb  findex_6.pb\n",
      "findex_1.pb  findex_3.pb  findex_5.pb  forwardindexdemo.pb\n"
     ]
    }
   ],
   "source": [
    "%ls Data/forward_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "27e1ea16-59b2-4c0b-a569-68d0e8f73ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total final docs =  70000\n"
     ]
    }
   ],
   "source": [
    "metadata.totaldocs = 70000\n",
    "print(\"Total final docs = \", 70000)\n",
    "with open(metadatafile_path, \"wb\") as f:\n",
    "    f.write(metadata.SerializeToString())\n",
    "lexicon = lexproto.Lexicon()\n",
    "lexicon.wordlist.extend(lexicon_list)\n",
    "UpdateLexicon(lexicon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb26093-c08e-42cb-97e5-33ea0d781940",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
